{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TikwhxGwlqu7",
    "outputId": "fbf50959-f6ab-4470-9f9b-80b797d68a9a"
   },
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import datasets, utils, preprocessing\n",
    "from tensorflow.keras import models, losses, optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NvTVuv7OQDu",
    "outputId": "57a74792-1523-4719-cfaa-197f896804ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Comprobar versión de TensorFlow\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Fijar semilla\n",
    "seed(22)\n",
    "random.set_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NvTVuv7OQDu",
    "outputId": "57a74792-1523-4719-cfaa-197f896804ad"
   },
   "outputs": [],
   "source": [
    "#Fijar método y porcentaje de poda\n",
    "METHOD = 'apoz'\n",
    "PERCENT = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RObhOy1plxzm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "Found 3925 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# Crear un nuevo generador\n",
    "train_imagegen = ImageDataGenerator(\n",
    "        rescale=1./255,    \n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "test_imagegen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Cargar datos de entrenamiento\n",
    "train = train_imagegen.flow_from_directory(\"../../datasets/imagenette2-160/train/\",\n",
    "                                     class_mode=\"categorical\", \n",
    "                                     shuffle=True,\n",
    "                                     batch_size=32, \n",
    "                                     target_size=(160, 160))\n",
    "#  Cargar datos de validación\n",
    "val = test_imagegen.flow_from_directory(\"../../datasets/imagenette2-160/val/\", \n",
    "                                   class_mode=\"categorical\", \n",
    "                                   shuffle=True, \n",
    "                                   batch_size=32, \n",
    "                                   target_size=(160, 160))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cQvBRMQ7l6dK"
   },
   "outputs": [],
   "source": [
    "# Definición de hiperparámetros\n",
    "learning_rate = 0.0001 # learning rate\n",
    "lr_decay = 1e-6\n",
    "epochs = 4  # Número de epochs\n",
    "\n",
    "opt = optimizers.RMSprop(lr=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vQbNZj6vmEQM",
    "outputId": "41b74217-ce68-437a-a5a3-651723080a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLA PARTE DE PRUNING\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LA PARTE DE PRUNING\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 160, 160, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 160, 160, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 158, 158, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 158, 158, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 79, 79, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 79, 79, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 79, 79, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 77, 77, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 77, 77, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 38, 38, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 38, 38, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 36, 36, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 36, 36, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 9,566,506\n",
      "Trainable params: 9,566,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importar modelo Keras\n",
    "imagenettenet = models.load_model('../../models/IMAGENETTE_model/imagenetteNetKeras.h5')\n",
    "\n",
    "# Verificar que el modelo es el correcto\n",
    "imagenettenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8QQmGYfmEtm",
    "outputId": "a666d038-d446-46a1-b25a-4394a787ebe2"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from kerassurgeon import Surgeon, identify\n",
    "from kerassurgeon.operations import delete_channels, delete_layer\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "  \n",
    "def get_filter_weights(model, layer=None):\n",
    "    \"\"\"function to return weights array for one or all conv layers of a Keras model\"\"\"\n",
    "    if layer or layer==0:\n",
    "        weight_array = model.layers[layer].get_weights()[0]\n",
    "        \n",
    "    else:\n",
    "        weights = [model.layers[layer_ix].get_weights()[0] for layer_ix in range(len(model.layers))\\\n",
    "         if 'conv' in model.layers[layer_ix].name]\n",
    "        weight_array = [np.array(i) for i in weights]\n",
    "    \n",
    "    return weight_array\n",
    "\n",
    "def get_filters_l1(model, layer=None):\n",
    "    \"\"\"Returns L1 norm of a Keras model filters at a given conv layer, if layer=None, returns a matrix of norms\n",
    "model is a Keras model\"\"\"\n",
    "    if layer or layer==0:\n",
    "        weights = get_filter_weights(model, layer)\n",
    "        num_filter = len(weights[0,0,0,:])\n",
    "        norms_dict = {}\n",
    "        norms = []\n",
    "        for i in range(num_filter):\n",
    "            l1_norm = np.sum(abs(weights[:,:,:,i]))\n",
    "            norms.append(l1_norm)\n",
    "    else:\n",
    "        weights = get_filter_weights(model)\n",
    "        max_kernels = max([layr.shape[3] for layr in weights])\n",
    "        norms = np.empty((len(weights), max_kernels))\n",
    "        norms[:] = np.NaN\n",
    "        for layer_ix in range(len(weights)):\n",
    "            # compute norm of the filters\n",
    "            kernel_size = weights[layer_ix][:,:,:,0].size\n",
    "            nb_filters = weights[layer_ix].shape[3]\n",
    "            kernels = weights[layer_ix]\n",
    "            l1 = [np.sum(abs(kernels[:,:,:,i])) for i in range(nb_filters)]\n",
    "            # divide by shape of the filters\n",
    "            l1 = np.array(l1) / kernel_size\n",
    "            norms[layer_ix, :nb_filters] = l1\n",
    "    return norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yFiJt2HimHn0"
   },
   "outputs": [],
   "source": [
    "def get_filters_apoz(model, layer=None):\n",
    "    \n",
    "    # Get a sample of the train set , or should it be the validation set ?\n",
    "    test_generator = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "    apoz_generator = test_generator.flow_from_directory(\n",
    "                \"../../datasets/imagenette2-160/train/\",\n",
    "                batch_size = 1,\n",
    "                subset='validation',\n",
    "                shuffle = False)\n",
    "    \n",
    "    if layer or layer ==0:\n",
    "        assert 'conv' in model.layers[layer].name, \"The layer provided is not a convolution layer\"\n",
    "        weights_array = get_filter_weights(model, layer)\n",
    "        act_ix = layer + 1\n",
    "        nb_filters = weights_array.shape[3]\n",
    "        apoz = compute_apoz(model, act_ix, nb_filters, apoz_generator)\n",
    "                \n",
    "    else :\n",
    "        weights_array = get_filter_weights(model)\n",
    "        max_kernels = max([layr.shape[3] for layr in weights_array])\n",
    "\n",
    "        conv_indexes = [i for i, v in enumerate(model.layers) if 'conv' in v.name]\n",
    "        print('------------------------------------------------')\n",
    "        activations_indexes = [i for i,v in enumerate(model.layers) if 'activation' \\\n",
    "                       in v.name and 'conv' in model.layers[i-1].name]\n",
    "        for i,v in enumerate(model.layers):\n",
    "          print(i)\n",
    "          print(v)\n",
    "        print('------------------------------------------------')\n",
    "        # create nd array to collect values\n",
    "        apoz = np.zeros((len(weights_array), max_kernels))\n",
    "\n",
    "        for i, act_ix in enumerate(activations_indexes):\n",
    "            # score this sample with our model (trimmed to the layer of interest)\n",
    "            nb_filters = weights_array[i].shape[3]\n",
    "            apoz_layer = compute_apoz(model, act_ix, nb_filters, apoz_generator)\n",
    "            print('APOZ de la capa {}:'.format(i))\n",
    "            print(apoz_layer)\n",
    "            apoz[i, :nb_filters] = apoz_layer\n",
    "        \n",
    "    return apoz\n",
    "\n",
    "\n",
    "def compute_apoz(model, layer_ix, nb_filters, generator):\n",
    "    \"\"\"Compute Average percentage of zeros over a layers activation maps\"\"\"\n",
    "    act_layer = model.get_layer(index=layer_ix)\n",
    "    node_index = 0\n",
    "    temp_model = Model(model.inputs,\n",
    "                               act_layer.get_output_at(node_index)\n",
    "                              )\n",
    "\n",
    "\n",
    "            # count the percentage of zeros per activation\n",
    "    a = temp_model.predict_generator(generator,944, workers=3, verbose=1)\n",
    "    activations = a.reshape(a.shape[0]*a.shape[1]*a.shape[2],nb_filters).T\n",
    "    apoz_layer = np.sum(activations == 0, axis=1) / activations.shape[1]\n",
    "    \n",
    "    return apoz_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XhppIK899EpC"
   },
   "outputs": [],
   "source": [
    "#function to return pruned filters with apoz method\n",
    "def prune_apoz(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    if layer or layer==0:\n",
    "        apoz = get_filters_apoz(model,layer)\n",
    "        to_prune = np.argsort(apoz)[::-1][:n_pruned]\n",
    "    \n",
    "    else:\n",
    "        apoz = get_filters_apoz(model)\n",
    "        print(apoz)\n",
    "        print('-------------')\n",
    "        to_prune = biggest_indices(apoz, n_pruned)\n",
    "        print('to prune')\n",
    "        print(to_prune)\n",
    "    \n",
    "    return to_prune\n",
    "\n",
    "#function to return pruned filters with l1 method\n",
    "def prune_l1(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    if layer or layer==0:\n",
    "        norms = get_filters_l1(model,layer)\n",
    "        to_prune = np.argsort(norms)[:n_pruned]\n",
    "    \n",
    "    else:\n",
    "        norms = get_filters_l1(model)\n",
    "        to_prune = smallest_indices(norms, n_pruned)\n",
    "    \n",
    "    return to_prune\n",
    "\n",
    "def prune_random(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    weights = get_filter_weights(model, layer)\n",
    "    if layer or layer==0:\n",
    "        n_filters = weights.shape[3]\n",
    "        to_prune = np.random.choice(range(n_filters), n_pruned, replace=False)\n",
    "    else:\n",
    "        layer_ix = np.random.choice(len(weights))\n",
    "        filters = weights[layer_ix].shape[3]\n",
    "        filter_ix = np.random.choice(range(filters))\n",
    "        to_prune = [[layer_ix, filter_ix]]\n",
    "\n",
    "        for i in range(n_pruned-1):\n",
    "            while [layer_ix, filter_ix] in to_prune :\n",
    "                #choose layer\n",
    "                layer_ix = np.random.choice(len(weights))\n",
    "                #choose filter \n",
    "                filters = weights[layer_ix].shape[3]\n",
    "                filter_ix = np.random.choice(range(filters))\n",
    "            to_prune.append([layer_ix, filter_ix])\n",
    "\n",
    "        to_prune = np.array(to_prune)\n",
    "    return to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tg74IXvcmKmZ"
   },
   "outputs": [],
   "source": [
    "def compute_pruned_count(model, perc=0.1, layer=None):\n",
    "    if layer or layer ==0:\n",
    "        # count nb of filters\n",
    "        nb_filters = model.layers[layer].output_shape[3]\n",
    "    else:\n",
    "        nb_filters = np.sum([model.layers[i].output_shape[3] for i, layer in enumerate(model.layers) \n",
    "                                if 'conv' in model.layers[i].name])\n",
    "            \n",
    "    n_pruned = int(np.floor(perc*nb_filters))\n",
    "    return n_pruned\n",
    "\n",
    "\n",
    "def smallest_indices(array, N):\n",
    "    idx = array.ravel().argsort()[:N]\n",
    "    return np.stack(np.unravel_index(idx, array.shape)).T\n",
    "\n",
    "def biggest_indices(array, N):\n",
    "    idx = array.ravel().argsort()[::-1][:N]\n",
    "    return np.stack(np.unravel_index(idx, array.shape)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DRYFjOF6mMXA"
   },
   "outputs": [],
   "source": [
    "from kerassurgeon.operations import delete_channels, delete_layer\n",
    "from kerassurgeon import Surgeon\n",
    "\n",
    "def prune_one_layer(model, pruned_indexes, layer_ix, opt):\n",
    "    \"\"\"Prunes one layer based on a Keras Model, layer index \n",
    "    and indexes of filters to prune\"\"\"\n",
    "    model_pruned = delete_channels(model, model.layers[layer_ix], pruned_indexes)\n",
    "    model_pruned.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "    return model_pruned\n",
    "\n",
    "def prune_multiple_layers(model, pruned_matrix, opt):\n",
    "    \"\"\"Prunes several layers based on a Keras Model, layer index and matrix \n",
    "    of indexes of filters to prune\"\"\"\n",
    "    conv_indexes = [i for i, v in enumerate(model.layers) if 'conv' in v.name]\n",
    "    layers_to_prune = np.unique(pruned_matrix[:,0])\n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    to_prune = pruned_matrix\n",
    "    to_prune[:,0] = np.array([conv_indexes[i] for i in to_prune[:,0]])\n",
    "    layers_to_prune = np.unique(to_prune[:,0])\n",
    "    for layer_ix in layers_to_prune :\n",
    "        pruned_filters = [x[1] for x in to_prune if x[0]==layer_ix]\n",
    "        print('filtros a podar:')\n",
    "        print(pruned_filters)\n",
    "        pruned_layer = model.layers[layer_ix]\n",
    "        print('capa a podar:')\n",
    "        print(pruned_layer)\n",
    "        surgeon.add_job('delete_channels', pruned_layer, channels=pruned_filters)\n",
    "    \n",
    "    model_pruned = surgeon.operate()\n",
    "    model_pruned.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QngxSqW3mOXi"
   },
   "outputs": [],
   "source": [
    "def prune_model(model, perc, opt, method='l1', layer=None):\n",
    "    \"\"\"Prune a Keras model using different methods\n",
    "    Arguments:\n",
    "        model: Keras Model object\n",
    "        perc: a float between 0 and 1\n",
    "        method: method to prune, can be one of ['l1','apoz','random']\n",
    "    Returns:\n",
    "        A pruned Keras Model object\n",
    "    \n",
    "    \"\"\"\n",
    "    assert method in ['l1','apoz','random'], \"Invalid pruning method\"\n",
    "    assert perc >=0 and perc <1, \"Invalid pruning percentage\"\n",
    "    \n",
    "    \n",
    "    n_pruned = compute_pruned_count(model, perc, layer)\n",
    "    \n",
    "    if method =='l1':\n",
    "        to_prune = prune_l1(model, n_pruned, layer)    \n",
    "    if method =='apoz':\n",
    "        to_prune = prune_apoz(model, n_pruned, layer)\n",
    "    if method =='random':\n",
    "        to_prune = prune_random(model, n_pruned, layer)    \n",
    "    if layer or layer ==0:\n",
    "        model_pruned = prune_one_layer(model, to_prune, layer, opt)\n",
    "    else:\n",
    "        model_pruned = prune_multiple_layers(model, to_prune, opt)\n",
    "            \n",
    "    return model_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqnPEc4amQu2",
    "outputId": "7acae651-8407-4ed0-ca1c-c0c06ff6140c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 944 images belonging to 10 classes.\n",
      "------------------------------------------------\n",
      "0\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feb1645feb8>\n",
      "1\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feb05eb48d0>\n",
      "2\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feb05eb4be0>\n",
      "3\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee7ed5f8>\n",
      "4\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7feaee7ed9b0>\n",
      "5\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7feaee7edbe0>\n",
      "6\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7fd710>\n",
      "7\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee7a1a58>\n",
      "8\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7b01d0>\n",
      "9\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee7b0c50>\n",
      "10\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7feaee7b0f28>\n",
      "11\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7feaee7b9128>\n",
      "12\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7b9c88>\n",
      "13\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee74d550>\n",
      "14\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee74d7b8>\n",
      "15\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee755278>\n",
      "16\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7feaee755550>\n",
      "17\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7feaee755780>\n",
      "18\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee75d2b0>\n",
      "19\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee767b38>\n",
      "20\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee767da0>\n",
      "21\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaf8ec1080>\n",
      "22\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7feaf8e87550>\n",
      "23\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7feb03df4ba8>\n",
      "24\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x7feaf8e3fc50>\n",
      "25\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7feaf8e59320>\n",
      "26\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee77a550>\n",
      "27\n",
      "<tensorflow.python.keras.layers.core.Dropout object at 0x7feaee77a710>\n",
      "28\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x7feaee77aa20>\n",
      "29\n",
      "<tensorflow.python.keras.layers.core.Activation object at 0x7feaee710cc0>\n",
      "------------------------------------------------\n",
      "WARNING:tensorflow:From <ipython-input-9-a7a99528105a>:55: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-a7a99528105a>:55: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 6s 6ms/step\n",
      "APOZ de la capa 0:\n",
      "[0.73911319 0.03153271 0.08403932 0.55220159 0.84672891 0.2594171\n",
      " 0.04552552 0.19538461 0.68302547 0.22029893 0.03485099 0.30768205\n",
      " 0.81283322 0.68552103 0.43990311 0.02541914 0.72524808 0.3987718\n",
      " 0.88675686 0.03679697 0.01163717 0.0163951  0.30322401 0.98730533\n",
      " 0.80095744 0.35663209 0.6023953  0.48139347 0.03497138 0.1232472\n",
      " 0.67666361 0.06910825]\n",
      "944/944 [==============================] - 7s 8ms/step\n",
      "APOZ de la capa 1:\n",
      "[0.74362747 0.30262949 0.79688796 0.61894601 0.75150452 0.74338615\n",
      " 0.93263976 0.74419369 0.55680032 0.86683183 0.45312168 0.7800632\n",
      " 0.85483553 0.67097736 0.64346024 0.63283045 0.29059788 0.48233001\n",
      " 0.82816365 0.182555   0.60533846 0.51948114 0.75009868 0.66499927\n",
      " 0.64840176 0.4962607  0.73449099 0.24237106 0.58222422 0.55829021\n",
      " 0.69492619 0.62856338]\n",
      "944/944 [==============================] - 11s 12ms/step\n",
      "APOZ de la capa 2:\n",
      "[0.53851252 0.68628174 0.64239833 0.64516567 0.67254845 0.24526842\n",
      " 0.33219824 0.54811965 0.26344293 0.30476056 0.46322742 0.54580299\n",
      " 0.52923391 0.8681329  0.6076286  0.2454491  0.69922104 0.5725852\n",
      " 0.49946039 0.3486927  0.41426289 0.74506495 0.24085367 0.79590584\n",
      " 0.7834289  0.50406817 0.68319244 0.21459721 0.71073067 0.67997828\n",
      " 0.83736435 0.83027243 0.08067819 0.41569369 0.35153308 0.04911224\n",
      " 0.47535364 0.44892661 0.56322049 0.19196059 0.64196577 0.48755584\n",
      " 0.26116482 0.2098542  0.55269787 0.43137867 0.66457362 0.39234434\n",
      " 0.54606143 0.77327284 0.34814029 0.44188776 0.28230811 0.52421341\n",
      " 0.5132562  0.61560094 0.15244261 0.37207358 0.78270027 0.26548473\n",
      " 0.46560024 0.51567447 0.37550454 0.41329769]\n",
      "944/944 [==============================] - 14s 15ms/step\n",
      "APOZ de la capa 3:\n",
      "[0.7783242  0.86261295 0.23278427 0.4441539  0.64103553 0.88983837\n",
      " 0.86062725 0.84617342 0.91219973 0.55901519 0.44004251 0.462896\n",
      " 0.80470949 0.34420034 0.74397302 0.63388983 0.54460664 0.54725092\n",
      " 0.39380786 0.45218353 0.8245118  0.67030319 0.32692014 0.66131417\n",
      " 0.49525031 0.3832339  0.82899275 0.79743085 0.5403438  0.77162014\n",
      " 0.67738522 0.35309017 0.87575451 0.60268569 0.53300658 0.61094692\n",
      " 0.8232259  0.74303302 0.4817061  0.73868285 0.54724285 0.33335105\n",
      " 0.75321336 0.44038868 0.68522183 0.36235173 0.78736488 0.71850353\n",
      " 0.69011654 0.52696122 0.74613125 0.55771132 0.44129959 0.40032237\n",
      " 0.51645268 0.89229708 0.68818583 0.5970358  0.44560386 0.47655058\n",
      " 0.83358142 0.74873844 0.43188868 0.7041139 ]\n",
      "944/944 [==============================] - 16s 16ms/step\n",
      "APOZ de la capa 4:\n",
      "[0.40564152 0.55604045 0.29422669 0.17105571 0.63747514 0.36120318\n",
      " 0.49871553 0.26429589 0.61220326 0.55042996 0.49556402 0.83544959\n",
      " 0.59847947 0.72050433 0.58888164 0.1883565  0.17889728 0.36012567\n",
      " 0.26710044 0.27944689 0.55205118 0.44514509 0.17003607 0.36243116\n",
      " 0.26032591 0.44682859 0.58238048 0.54366589 0.67799807 0.55031036\n",
      " 0.30314578 0.38899909 0.52092878 0.38939482 0.48565782 0.43847196\n",
      " 0.59619824 0.3893138  0.41109384 0.60321197 0.43229791 0.39083141\n",
      " 0.39962207 0.67405179 0.44353075 0.42017909 0.28605085 0.66698873\n",
      " 0.45374974 0.32586581 0.24688514 0.25834561 0.30518368 0.1890143\n",
      " 0.67814302 0.35910135 0.46925403 0.63164639 0.84888319 0.48592154\n",
      " 0.45697731 0.3984776  0.48915325 0.49834901 0.18906225 0.58714109\n",
      " 0.44156009 0.45832406 0.23479994 0.37165558 0.69713917 0.44895606\n",
      " 0.29459707 0.69330919 0.56123482 0.43766287 0.30482928 0.36983953\n",
      " 0.28989874 0.33975026 0.54141718 0.50179842 0.55612616 0.42920042\n",
      " 0.13272859 0.25977338 0.19805409 0.45439817 0.40157978 0.27583599\n",
      " 0.80503487 0.60483706 0.33125171 0.72095407 0.37859271 0.69319399\n",
      " 0.36981665 0.34319195 0.17615721 0.48590115 0.55427317 0.58760654\n",
      " 0.27610771 0.24466508 0.12733084 0.87988738 0.39784018 0.38852758\n",
      " 0.49518097 0.40146183 0.50400387 0.65419364 0.64351471 0.45561898\n",
      " 0.50973645 0.45145858 0.51289457 0.64863385 0.20712998 0.2568776\n",
      " 0.33209443 0.24944747 0.40464751 0.39199187 0.38660569 0.79440362\n",
      " 0.44028279 0.22248188]\n",
      "944/944 [==============================] - 18s 19ms/step\n",
      "APOZ de la capa 5:\n",
      "[0.2351589  0.35359875 0.30472281 0.49402984 0.56205508 0.64112965\n",
      " 0.22056173 0.43474047 0.48962659 0.26946004 0.71956656 0.32157721\n",
      " 0.30577595 0.4719159  0.45803672 0.30850547 0.49467661 0.34694444\n",
      " 0.23928967 0.66357727 0.38024394 0.52226312 0.48445739 0.27403278\n",
      " 0.31702125 0.6853178  0.73217367 0.27453655 0.65044903 0.5017061\n",
      " 0.54974076 0.27585099 0.63079979 0.40590366 0.55132003 0.59812883\n",
      " 0.38603284 0.28588512 0.27003413 0.23412724 0.7476027  0.59224253\n",
      " 0.30236288 0.77099959 0.44720957 0.30675583 0.51424641 0.5469006\n",
      " 0.52469133 0.63432233 0.52823829 0.58706921 0.63035428 0.62444062\n",
      " 0.13455361 0.30851371 0.61768774 0.6336679  0.55090248 0.27923876\n",
      " 0.34861641 0.41219368 0.25437941 0.23871587 0.26643126 0.48712012\n",
      " 0.71652189 0.24317385 0.66402513 0.63892126 0.49175671 0.70576595\n",
      " 0.48474194 0.48846428 0.41172493 0.42817238 0.33712924 0.55762535\n",
      " 0.29923346 0.43398629 0.47025041 0.33806733 0.45946593 0.51653778\n",
      " 0.38729696 0.42066649 0.66642361 0.29505856 0.42671022 0.39964866\n",
      " 0.5769159  0.57854961 0.6905123  0.68958422 0.52422669 0.56953831\n",
      " 0.33227519 0.38904161 0.47905691 0.54315737 0.26650924 0.69817149\n",
      " 0.31216926 0.5373155  0.2425053  0.43361876 0.26222281 0.57662017\n",
      " 0.69723929 0.36686794 0.82629355 0.51308057 0.43739171 0.56824476\n",
      " 0.47386505 0.51991025 0.38841955 0.67791225 0.46155838 0.73777807\n",
      " 0.43687912 0.23932233 0.59364583 0.29060411 0.28881621 0.57707245\n",
      " 0.66466337 0.5758348 ]\n",
      "944/944 [==============================] - 19s 21ms/step\n",
      "APOZ de la capa 6:\n",
      "[1.52119821e-01 2.86055791e-01 1.23348635e-01 7.44116055e-01\n",
      " 5.80244821e-01 4.82498823e-01 7.16764360e-01 2.58945386e-05\n",
      " 4.80796846e-01 3.62800141e-01 3.08619350e-01 8.47257533e-02\n",
      " 3.00770951e-01 2.23202684e-01 7.31005179e-01 6.18561676e-01\n",
      " 1.82690678e-01 3.23069680e-01 3.60894539e-01 1.37871940e-01\n",
      " 4.85486111e-01 2.66780838e-01 8.70974576e-02 8.41572505e-04\n",
      " 1.42501177e-01 2.73761770e-01 6.70982815e-01 2.48604049e-01\n",
      " 2.66924435e-01 2.36107580e-01 3.22634181e-01 4.33233286e-01\n",
      " 7.45056497e-02 6.69193738e-01 1.31709040e-01 2.35103578e-01\n",
      " 2.30057674e-01 7.59216102e-02 5.55885122e-01 1.40065913e-04\n",
      " 1.90796846e-01 5.23594633e-01 4.70893362e-01 2.81206450e-01\n",
      " 7.44864642e-01 2.18840631e-01 4.27277542e-01 3.72680085e-01\n",
      " 2.71989171e-01 3.24568032e-01 2.52727166e-01 3.95108286e-01\n",
      " 1.38183851e-01 1.10316620e-01 1.99180791e-01 3.62595339e-01\n",
      " 4.22647128e-01 1.85105932e-01 2.02117467e-01 5.82801318e-01\n",
      " 6.37229284e-01 3.41373588e-01 3.52567090e-01 1.49812853e-01\n",
      " 4.40036488e-01 3.36676083e-01 3.83454567e-01 4.17725989e-03\n",
      " 7.47411723e-01 5.31259416e-01 1.90177731e-01 1.00765066e-02\n",
      " 4.35816855e-02 2.59885829e-01 3.69437382e-01 6.73001412e-01\n",
      " 2.83819444e-01 2.93799435e-01 3.87730697e-01 4.35169492e-02\n",
      " 5.12350518e-01 4.60740348e-01 1.50338983e-01 5.21379473e-01\n",
      " 3.66577213e-01 4.80394303e-01 5.80494350e-01 4.08074388e-03\n",
      " 3.50701507e-01 1.14495056e-01 6.54066620e-01 3.94642185e-01\n",
      " 8.84298493e-03 5.08629944e-01 4.61690207e-01 1.89568032e-01\n",
      " 2.09738701e-01 3.76319444e-01 4.16426554e-01 2.92528249e-01\n",
      " 1.96100518e-01 6.73651130e-01 5.34878766e-01 2.49345574e-01\n",
      " 2.99724576e-01 1.22161017e-01 6.27953154e-01 3.25537900e-01\n",
      " 1.73210923e-01 8.01153484e-02 6.23858286e-02 6.30592043e-01\n",
      " 3.36904426e-01 9.27495292e-03 4.78607580e-01 1.16000471e-01\n",
      " 7.68373352e-02 3.61486582e-01 7.26605461e-01 5.57036252e-01\n",
      " 4.96281780e-01 5.26533663e-01 1.88323917e-05 5.73644068e-01\n",
      " 6.61134652e-03 5.46144068e-01 3.37397599e-01 6.30920433e-01\n",
      " 6.31470104e-01 4.19337335e-01 8.60911017e-02 9.58910075e-02\n",
      " 9.08039077e-02 5.35728578e-01 6.15304849e-01 5.63678202e-01\n",
      " 4.95494350e-01 2.07601224e-01 2.50501412e-01 4.14362053e-01\n",
      " 6.51231168e-01 1.71528955e-01 5.22717750e-01 5.88274482e-01\n",
      " 5.13569915e-01 2.24905838e-01 1.81334746e-01 6.37735405e-02\n",
      " 3.38606403e-02 7.35087100e-02 1.28342750e-01 5.84572740e-01\n",
      " 6.23472222e-01 3.45722693e-01 2.67024482e-01 4.56929143e-01\n",
      " 5.12570621e-02 3.48897128e-01 1.59850518e-01 1.39573917e-01\n",
      " 2.68774718e-01 1.55387241e-01 2.83046139e-01 6.01918550e-02\n",
      " 4.65251883e-01 1.04333804e-01 3.19651601e-01 4.79086629e-01\n",
      " 6.97294021e-01 1.66939736e-01 1.23599341e-02 4.97377589e-01\n",
      " 4.91583098e-01 5.52911959e-01 1.40920433e-01 6.21056968e-01\n",
      " 6.23925377e-01 4.70000000e-01 2.95774482e-01 3.74266714e-01\n",
      " 4.65471987e-01 3.56732580e-02 7.36244115e-01 3.50943974e-01\n",
      " 1.09299670e-01 5.41898540e-01 4.65348399e-02 5.67612994e-01\n",
      " 2.74923493e-01 2.20736817e-01 2.39350282e-01 8.42231638e-02\n",
      " 4.65077684e-01 1.70507298e-01 3.22525895e-01 3.89065443e-02\n",
      " 4.17645951e-01 2.82674200e-01 2.04173729e-01 2.23475753e-01\n",
      " 2.04413842e-01 5.05070621e-01 5.39274953e-01 3.55204802e-01\n",
      " 4.76433616e-01 7.23779426e-01 1.74436205e-01 1.73429849e-01\n",
      " 3.89230226e-01 4.19817561e-01 4.03307439e-01 3.42243409e-01\n",
      " 5.64004237e-01 3.68408663e-02 3.34956450e-01 9.98893597e-02\n",
      " 5.45127119e-02 5.47682439e-01 6.45294256e-01 4.63991290e-01\n",
      " 4.42011535e-01 2.54100753e-01 1.36169962e-01 2.79751648e-01\n",
      " 4.12020951e-01 2.20094162e-01 8.77436441e-02 4.85129473e-01\n",
      " 3.81519539e-01 3.15094162e-01 6.85098870e-02 9.02412900e-02\n",
      " 2.99180791e-01 9.60475518e-02 5.33545198e-03 5.91784369e-01\n",
      " 1.95614407e-01 3.80266008e-01 5.19625706e-01 3.65175377e-01\n",
      " 1.02197505e-01 3.33052024e-01 2.24039548e-01 2.31623117e-01\n",
      " 1.92558851e-01 5.43935970e-01 5.24613936e-01 4.11733757e-01\n",
      " 3.85892185e-01 1.51924435e-01 1.52919021e-01 3.62042137e-01\n",
      " 3.50297787e-01 6.11523070e-02 9.35793315e-02 1.28147363e-01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944/944 [==============================] - 22s 24ms/step\n",
      "APOZ de la capa 7:\n",
      "[1.         0.81629005 0.99989191 0.81992201 1.         1.\n",
      " 1.         0.87383258 0.69425993 1.         1.         0.91977662\n",
      " 0.92337075 0.99999865 1.         0.98712599 1.         1.\n",
      " 0.90931041 1.         1.         0.79326466 0.96440597 0.70858375\n",
      " 0.97463572 1.         0.9999946  1.         1.         1.\n",
      " 0.77672086 0.92378286 1.         0.97732727 1.         1.\n",
      " 1.         0.84045854 1.         0.9738669  1.         1.\n",
      " 0.99128762 0.96447488 0.96818926 0.81205141 1.         0.93929031\n",
      " 0.88912114 0.832719   0.95974576 1.         0.71153607 1.\n",
      " 1.         1.         0.90108175 1.         1.         0.96101992\n",
      " 0.83391614 0.95992547 1.         1.         0.9700674  0.91850382\n",
      " 0.82779666 1.         0.62835632 0.93942948 1.         1.\n",
      " 1.         1.         1.         1.         1.         0.82626578\n",
      " 0.99999865 1.         1.         0.98048226 0.94619887 0.95822839\n",
      " 1.         0.6775094  1.         0.8896535  1.         0.96417762\n",
      " 1.         1.         1.         0.922329   1.         0.8628813\n",
      " 1.         0.97896489 1.         1.         0.82538211 0.84563219\n",
      " 0.69457341 1.         1.         1.         1.         1.\n",
      " 0.9999973  0.9675988  0.84244612 0.98445742 1.         0.96374795\n",
      " 0.98261847 0.88946434 0.86616466 1.         0.91263836 0.93172778\n",
      " 1.         1.         0.99998243 1.         0.90859699 0.81725614\n",
      " 0.92066164 0.98707735 0.96581795 1.         1.         0.83445391\n",
      " 0.93921059 0.98244552 0.78605748 0.97547075 1.         1.\n",
      " 0.872072   1.         0.93162103 0.97700839 0.6183995  1.\n",
      " 1.         0.93120217 0.90847133 1.         0.97778937 1.\n",
      " 0.94631913 1.         1.         0.98734083 0.73543432 0.92133453\n",
      " 0.8520219  0.99547491 1.         0.91907131 0.9921294  1.\n",
      " 1.         1.         0.99998243 1.         0.89792676 0.96371822\n",
      " 0.94441937 1.         0.8930355  1.         1.         0.94591377\n",
      " 0.99463313 0.93240066 0.94595566 0.85947634 0.98874876 0.99087551\n",
      " 0.666246   0.96112531 1.         1.         1.         0.98111731\n",
      " 0.94671772 0.76549799 0.90782817 1.         0.94655153 1.\n",
      " 1.         1.         0.96525586 0.95806625 0.75457508 0.97164962\n",
      " 1.         0.95880534 0.92348425 1.         0.90742012 0.6912941\n",
      " 0.91289103 0.93644743 0.94757167 0.82623876 1.         1.\n",
      " 1.         0.90998195 1.         1.         1.         1.\n",
      " 0.96659082 0.9463475  1.         1.         1.         0.96100641\n",
      " 1.         1.         1.         0.99990812 0.971451   0.90999546\n",
      " 1.         0.94175215 1.         1.         0.8706884  1.\n",
      " 0.89496903 0.94247233 1.         0.75630729 0.97780693 1.\n",
      " 0.97801096 1.         1.         0.91035622 0.96691916 0.98721247\n",
      " 1.         1.         1.         0.73060522 1.         1.\n",
      " 1.         1.         0.99999865 0.9570299 ]\n",
      "[[0.73911319 0.03153271 0.08403932 ... 0.         0.         0.        ]\n",
      " [0.74362747 0.30262949 0.79688796 ... 0.         0.         0.        ]\n",
      " [0.53851252 0.68628174 0.64239833 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.2351589  0.35359875 0.30472281 ... 0.         0.         0.        ]\n",
      " [0.15211982 0.28605579 0.12334863 ... 0.06115231 0.09357933 0.12814736]\n",
      " [1.         0.81629005 0.99989191 ... 1.         0.99999865 0.9570299 ]]\n",
      "-------------\n",
      "to prune\n",
      "[[  7 105]\n",
      " [  7  51]\n",
      " [  7 151]\n",
      " [  7 149]\n",
      " [  7 147]\n",
      " [  7  46]\n",
      " [  7 144]\n",
      " [  7 143]\n",
      " [  7  53]\n",
      " [  7  29]\n",
      " [  7 139]\n",
      " [  7  54]\n",
      " [  7 137]\n",
      " [  7 136]\n",
      " [  7  55]\n",
      " [  7  57]\n",
      " [  7 152]\n",
      " [  7 158]\n",
      " [  7  41]\n",
      " [  7 161]\n",
      " [  7 162]\n",
      " [  7 163]\n",
      " [  7 165]\n",
      " [  7  40]\n",
      " [  7  38]\n",
      " [  7 171]\n",
      " [  7 172]\n",
      " [  7  36]\n",
      " [  7  35]\n",
      " [  7  34]\n",
      " [  7  32]\n",
      " [  7 182]\n",
      " [  7 183]\n",
      " [  7  58]\n",
      " [  7 130]\n",
      " [  7 129]\n",
      " [  7  74]\n",
      " [  7  84]\n",
      " [  7  80]\n",
      " [  7  86]\n",
      " [  7  79]\n",
      " [  7  88]\n",
      " [  7  90]\n",
      " [  7  91]\n",
      " [  7  92]\n",
      " [  7  94]\n",
      " [  7  76]\n",
      " [  7  96]\n",
      " [  7  98]\n",
      " [  7  99]\n",
      " [  7  75]\n",
      " [  7  73]\n",
      " [  7  62]\n",
      " [  7 103]\n",
      " [  7 104]\n",
      " [  7  72]\n",
      " [  7 106]\n",
      " [  7 107]\n",
      " [  7  71]\n",
      " [  7 112]\n",
      " [  7  70]\n",
      " [  7  67]\n",
      " [  7 117]\n",
      " [  7  63]\n",
      " [  7 120]\n",
      " [  7 121]\n",
      " [  7 123]\n",
      " [  7 184]\n",
      " [  7 169]\n",
      " [  7  28]\n",
      " [  7 220]\n",
      " [  7   9]\n",
      " [  7 228]\n",
      " [  7  10]\n",
      " [  7 224]\n",
      " [  7 223]\n",
      " [  7 222]\n",
      " [  7 219]\n",
      " [  7 231]\n",
      " [  7 215]\n",
      " [  7 214]\n",
      " [  7 213]\n",
      " [  7 212]\n",
      " [  7  14]\n",
      " [  7 210]\n",
      " [  7 230]\n",
      " [  7   6]\n",
      " [  7 208]\n",
      " [  7 246]\n",
      " [  7 253]\n",
      " [  7 252]\n",
      " [  7 251]\n",
      " [  7 250]\n",
      " [  7 248]\n",
      " [  7 247]\n",
      " [  7   0]\n",
      " [  7 233]\n",
      " [  7 242]\n",
      " [  7 241]\n",
      " [  7 239]\n",
      " [  7 236]\n",
      " [  7   4]\n",
      " [  7   5]\n",
      " [  7 209]\n",
      " [  7 218]\n",
      " [  7 198]\n",
      " [  7 191]\n",
      " [  7  16]\n",
      " [  7  17]\n",
      " [  7  27]\n",
      " [  7 193]\n",
      " [  7  25]\n",
      " [  7 189]\n",
      " [  7  20]\n",
      " [  7 192]\n",
      " [  7  19]\n",
      " [  7 201]\n",
      " [  7  13]\n",
      " [  7 254]\n",
      " [  7  78]\n",
      " [  7 108]\n",
      " [  7  26]\n",
      " [  7 164]\n",
      " [  7 122]\n",
      " [  7 225]\n",
      " [  7   2]\n",
      " [  7 157]\n",
      " [  7 174]\n",
      " [  7 160]\n",
      " [  7  42]\n",
      " [  7 179]\n",
      " [  7 178]\n",
      " [  7 153]\n",
      " [  0  23]\n",
      " [  7 245]\n",
      " [  7  15]\n",
      " [  7 127]\n",
      " [  7 111]\n",
      " [  7 114]\n",
      " [  7 133]\n",
      " [  7 185]\n",
      " [  7  81]\n",
      " [  7  97]\n",
      " [  7 240]\n",
      " [  7 238]\n",
      " [  7 148]\n",
      " [  7  33]\n",
      " [  7 141]\n",
      " [  7 135]\n",
      " [  7  24]\n",
      " [  7  39]\n",
      " [  7 197]\n",
      " [  7 226]\n",
      " [  7  64]\n",
      " [  7  44]\n",
      " [  7 109]\n",
      " [  7 244]\n",
      " [  7 216]\n",
      " [  7 128]\n",
      " [  7 194]\n",
      " [  7  43]\n",
      " [  7  22]\n",
      " [  7  89]\n",
      " [  7 113]\n",
      " [  7 167]\n",
      " [  7 181]\n",
      " [  7  59]\n",
      " [  7 221]\n",
      " [  7  61]\n",
      " [  7  50]\n",
      " [  7 199]\n",
      " [  7  83]\n",
      " [  7 195]\n",
      " [  7 255]\n",
      " [  7 206]\n",
      " [  7 186]\n",
      " [  7 190]\n",
      " [  7 217]\n",
      " [  7 150]\n",
      " [  7  82]\n",
      " [  7 176]\n",
      " [  7 173]\n",
      " [  7 168]\n",
      " [  7 235]\n",
      " [  7 229]\n",
      " [  7  69]\n",
      " [  7  47]\n",
      " [  7 132]\n",
      " [  7 205]\n",
      " [  1   6]\n",
      " [  7 175]\n",
      " [  7 119]\n",
      " [  7 140]\n",
      " [  7 145]\n",
      " [  7  31]\n",
      " [  7 200]\n",
      " [  7  12]\n",
      " [  7  93]\n",
      " [  7 155]\n",
      " [  7 126]\n",
      " [  7  11]\n",
      " [  7 159]\n",
      " [  7  65]\n",
      " [  7 204]\n",
      " [  7 118]\n",
      " [  3   8]\n",
      " [  7 243]\n",
      " [  7 227]\n",
      " [  7 211]\n",
      " [  7  18]\n",
      " [  7 124]\n",
      " [  7 146]\n",
      " [  7 188]\n",
      " [  7 202]\n",
      " [  7  56]\n",
      " [  7 166]\n",
      " [  7 234]\n",
      " [  7 170]\n",
      " [  3  55]\n",
      " [  3   5]\n",
      " [  7  87]\n",
      " [  7 115]\n",
      " [  7  48]\n",
      " [  0  18]\n",
      " [  4 105]\n",
      " [  3  32]\n",
      " [  7   7]\n",
      " [  7 138]\n",
      " [  7 232]\n",
      " [  2  13]\n",
      " [  1   9]\n",
      " [  7 116]\n",
      " [  7  95]\n",
      " [  3   1]\n",
      " [  3   6]\n",
      " [  7 177]\n",
      " [  1  12]\n",
      " [  7 156]\n",
      " [  4  58]\n",
      " [  0   4]\n",
      " [  3   7]\n",
      " [  7 101]\n",
      " [  7 110]\n",
      " [  7  37]\n",
      " [  2  30]\n",
      " [  4  11]\n",
      " [  7 131]\n",
      " [  7  60]\n",
      " [  3  60]\n",
      " [  7  49]\n",
      " [  2  31]\n",
      " [  3  26]\n",
      " [  1  18]\n",
      " [  7  66]\n",
      " [  5 110]\n",
      " [  7  77]\n",
      " [  7 207]\n",
      " [  7 100]\n",
      " [  3  20]\n",
      " [  3  36]\n",
      " [  7   3]\n",
      " [  7 125]\n",
      " [  7   1]\n",
      " [  0  12]\n",
      " [  7  45]\n",
      " [  4  90]\n",
      " [  3  12]\n",
      " [  0  24]\n",
      " [  3  27]\n",
      " [  1   2]\n",
      " [  2  23]\n",
      " [  4 125]\n",
      " [  7  21]\n",
      " [  3  46]\n",
      " [  7 134]\n",
      " [  2  24]\n",
      " [  2  58]\n",
      " [  1  11]\n",
      " [  3   0]\n",
      " [  7  30]\n",
      " [  2  49]\n",
      " [  3  29]\n",
      " [  5  43]\n",
      " [  7 187]\n",
      " [  7 237]\n",
      " [  7 196]\n",
      " [  3  42]\n",
      " [  1   4]\n",
      " [  1  22]\n",
      " [  3  61]\n",
      " [  5  40]\n",
      " [  6  68]\n",
      " [  3  50]\n",
      " [  2  21]\n",
      " [  6  44]\n",
      " [  1   7]\n",
      " [  6   3]\n",
      " [  3  14]\n",
      " [  1   0]\n",
      " [  1   5]\n",
      " [  3  37]\n",
      " [  0   0]\n",
      " [  3  39]\n",
      " [  5 119]\n",
      " [  6 182]\n",
      " [  7 154]\n",
      " [  1  26]\n",
      " [  5  26]\n",
      " [  6  14]\n",
      " [  7 249]\n",
      " [  6 118]\n",
      " [  0  16]\n",
      " [  6 205]\n",
      " [  4  93]\n",
      " [  4  13]\n",
      " [  5  10]\n",
      " [  3  47]\n",
      " [  6   6]\n",
      " [  5  66]\n",
      " [  7  52]\n",
      " [  2  28]\n",
      " [  7  23]\n",
      " [  5  71]\n",
      " [  3  63]\n",
      " [  2  16]\n",
      " [  5 101]\n",
      " [  6 168]\n",
      " [  5 108]\n",
      " [  4  70]\n",
      " [  1  30]\n",
      " [  7 102]\n",
      " [  7   8]\n",
      " [  4  73]\n",
      " [  4  95]\n",
      " [  7 203]\n",
      " [  5  92]\n",
      " [  3  48]\n",
      " [  5  93]\n",
      " [  3  56]\n",
      " [  2   1]\n",
      " [  0  13]\n",
      " [  5  25]\n",
      " [  3  44]\n",
      " [  2  26]\n",
      " [  0   8]\n",
      " [  2  29]\n",
      " [  4  54]\n",
      " [  4  28]\n",
      " [  5 117]\n",
      " [  7  85]\n",
      " [  3  30]\n",
      " [  0  30]\n",
      " [  4  43]\n",
      " [  6 101]\n",
      " [  6  75]\n",
      " [  2   4]\n",
      " [  6  26]\n",
      " [  1  13]\n",
      " [  3  21]\n",
      " [  6  33]\n",
      " [  4  47]\n",
      " [  5  86]\n",
      " [  7 180]\n",
      " [  1  23]\n",
      " [  5 126]\n",
      " [  2  46]\n",
      " [  5  68]\n",
      " [  5  19]\n",
      " [  3  23]\n",
      " [  4 111]\n",
      " [  6  90]\n",
      " [  6 140]\n",
      " [  5  28]\n",
      " [  4 117]\n",
      " [  1  24]\n",
      " [  6 218]\n",
      " [  2   3]\n",
      " [  4 112]\n",
      " [  1  14]\n",
      " [  2   2]\n",
      " [  2  40]\n",
      " [  5   5]\n",
      " [  3   4]\n",
      " [  5  69]]\n",
      "filtros a podar:\n",
      "[23, 18, 4, 12, 24, 0, 16, 13, 8, 30]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feb1645feb8>\n",
      "filtros a podar:\n",
      "[6, 9, 12, 18, 2, 11, 4, 22, 7, 0, 5, 26, 30, 13, 23, 24, 14]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feb05eb4be0>\n",
      "filtros a podar:\n",
      "[13, 30, 31, 23, 24, 58, 49, 21, 28, 16, 1, 26, 29, 4, 46, 3, 2, 40]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7fd710>\n",
      "filtros a podar:\n",
      "[8, 55, 5, 32, 1, 6, 7, 60, 26, 20, 36, 12, 27, 46, 0, 29, 42, 61, 50, 14, 37, 39, 47, 63, 48, 56, 44, 30, 21, 23, 4]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7b01d0>\n",
      "filtros a podar:\n",
      "[105, 58, 11, 90, 125, 93, 13, 70, 73, 95, 54, 28, 43, 47, 111, 117, 112]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee7b9c88>\n",
      "filtros a podar:\n",
      "[110, 43, 40, 119, 26, 10, 66, 71, 101, 108, 92, 93, 25, 117, 86, 126, 68, 19, 28, 5, 69]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee74d7b8>\n",
      "filtros a podar:\n",
      "[68, 44, 3, 182, 14, 118, 205, 6, 168, 101, 75, 26, 33, 90, 140, 218]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee75d2b0>\n",
      "filtros a podar:\n",
      "[105, 51, 151, 149, 147, 46, 144, 143, 53, 29, 139, 54, 137, 136, 55, 57, 152, 158, 41, 161, 162, 163, 165, 40, 38, 171, 172, 36, 35, 34, 32, 182, 183, 58, 130, 129, 74, 84, 80, 86, 79, 88, 90, 91, 92, 94, 76, 96, 98, 99, 75, 73, 62, 103, 104, 72, 106, 107, 71, 112, 70, 67, 117, 63, 120, 121, 123, 184, 169, 28, 220, 9, 228, 10, 224, 223, 222, 219, 231, 215, 214, 213, 212, 14, 210, 230, 6, 208, 246, 253, 252, 251, 250, 248, 247, 0, 233, 242, 241, 239, 236, 4, 5, 209, 218, 198, 191, 16, 17, 27, 193, 25, 189, 20, 192, 19, 201, 13, 254, 78, 108, 26, 164, 122, 225, 2, 157, 174, 160, 42, 179, 178, 153, 245, 15, 127, 111, 114, 133, 185, 81, 97, 240, 238, 148, 33, 141, 135, 24, 39, 197, 226, 64, 44, 109, 244, 216, 128, 194, 43, 22, 89, 113, 167, 181, 59, 221, 61, 50, 199, 83, 195, 255, 206, 186, 190, 217, 150, 82, 176, 173, 168, 235, 229, 69, 47, 132, 205, 175, 119, 140, 145, 31, 200, 12, 93, 155, 126, 11, 159, 65, 204, 118, 243, 227, 211, 18, 124, 146, 188, 202, 56, 166, 234, 170, 87, 115, 48, 7, 138, 232, 116, 95, 177, 156, 101, 110, 37, 131, 60, 49, 66, 77, 207, 100, 3, 125, 1, 45, 21, 134, 30, 187, 237, 196, 154, 249, 52, 23, 102, 8, 203, 85, 180]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7feaee767da0>\n",
      "Deleting 10/32 channels from layer: conv2d\n",
      "Deleting 17/32 channels from layer: conv2d_1\n",
      "Deleting 18/64 channels from layer: conv2d_2\n",
      "Deleting 31/64 channels from layer: conv2d_3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting 17/128 channels from layer: conv2d_4\n",
      "Deleting 21/128 channels from layer: conv2d_5\n",
      "Deleting 16/256 channels from layer: conv2d_6\n",
      "Deleting 254/256 channels from layer: conv2d_7\n",
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_input (InputLayer)    [(None, 160, 160, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 160, 160, 22)      616       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 160, 160, 22)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 158, 158, 15)      2985      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 158, 158, 15)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 79, 79, 15)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 79, 79, 15)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 79, 79, 46)        6256      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 79, 79, 46)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 77, 77, 33)        13695     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 77, 77, 33)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 38, 38, 33)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 38, 38, 33)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 38, 38, 111)       33078     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 38, 38, 111)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 36, 36, 107)       107000    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 36, 36, 107)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 107)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 107)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 18, 240)       231360    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 18, 18, 240)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 2)         4322      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 2)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 2)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 470,490\n",
      "Trainable params: 470,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Podar modelo\n",
    "model_pruned = prune_model(imagenettenet, PERCENT, opt, method=METHOD)\n",
    "model_pruned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-9b9e5c836964>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-15-9b9e5c836964>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "296/296 [==============================] - 220s 745ms/step - loss: 1.9518 - accuracy: 0.3147 - val_loss: 1.8207 - val_accuracy: 0.3664\n",
      "Epoch 2/4\n",
      "296/296 [==============================] - 217s 732ms/step - loss: 1.8235 - accuracy: 0.3670 - val_loss: 1.8380 - val_accuracy: 0.3483\n",
      "Epoch 3/4\n",
      "296/296 [==============================] - 220s 744ms/step - loss: 1.7665 - accuracy: 0.3931 - val_loss: 1.7275 - val_accuracy: 0.4099\n",
      "Epoch 4/4\n",
      "296/296 [==============================] - 219s 738ms/step - loss: 1.7295 - accuracy: 0.4049 - val_loss: 1.7084 - val_accuracy: 0.4224\n"
     ]
    }
   ],
   "source": [
    "# Fine tune\n",
    "history = model_pruned.fit_generator(\n",
    "          train,\n",
    "          epochs=epochs,\n",
    "          validation_data=val,\n",
    "          verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zHvxB8gIGmSm"
   },
   "outputs": [],
   "source": [
    "# Guardar a disco modelo de Keras en formato h5 y h5py\n",
    "model_pruned.save('imagenettenetKerasPruned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lucas/tfg-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lucas/tfg-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lucas/tfg-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/lucas/tfg-env/lib/python3.6/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpa8ftiybn/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpa8ftiybn/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnhi2szcj/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnhi2szcj/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "482784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir a Tensorflow Lite sin Cuantización\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\n",
    "tflite_model = converter.convert()\n",
    "# Guardar a disco\n",
    "open(\"imagenettenetTFLitePruned.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convertir a Tensorflow Lite con Cuantización de rango dinámico\n",
    "converter_q = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\n",
    "converter_q.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter_q.convert()\n",
    "# Guardar a disco\n",
    "open(\"imagenettenetTFLitePrunedQuant.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPARTE DE COMPARACIÓN DE TAMAÑOS\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PARTE DE COMPARACIÓN DE TAMAÑOS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño del modelo comprimido en Keras es 42549945.00 bytes\n",
      "------------------------------------------------------\n",
      "El tamaño del modelo comprimido en Keras PODADO es 3474911.00 bytes\n",
      "------------------------------------------------------\n",
      "El tamaño del modelo comprimido PODADO y en TFlite sin cuantizar es 1746747.00 bytes\n",
      "------------------------------------------------------\n",
      "El tamaño del modelo comprimido PODADO y en TFlite CUANTIZADO es 429913.00 bytes\n"
     ]
    }
   ],
   "source": [
    "# Comparación de tamaños\n",
    "print(\"El tamaño del modelo comprimido en Keras es %.2f bytes\" % get_gzipped_model_size('../../models/IMAGENETTE_model/imagenetteNetKeras.h5'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido en Keras PODADO es %.2f bytes\" % get_gzipped_model_size('imagenettenetKerasPruned.h5'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido PODADO y en TFlite sin cuantizar es %.2f bytes\" % get_gzipped_model_size('imagenettenetTFLitePruned.tflite'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido PODADO y en TFlite CUANTIZADO es %.2f bytes\" % get_gzipped_model_size('imagenettenetTFLitePrunedQuant.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPARTE DE COMPARACIÓN DE PRECISIÓN Y TOMA DE TIEMPOS\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PARTE DE COMPARACIÓN DE PRECISIÓN Y TOMA DE TIEMPOS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 20s 164ms/step - loss: 1.0759 - accuracy: 0.7045\n",
      "\n",
      "accuracy: 70.45%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "\n",
    "# Probaremos la precisión del modelo de Keras sin podar\n",
    "scores = imagenettenet.evaluate(val, batch_size=1, verbose=1)\n",
    "print(\"\\n%s: %.2f%%\" % (imagenettenet.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, test_batches, quantized):\n",
    "\n",
    "    # lista de tiempos \n",
    "    times=[]\n",
    "    # contador para el iterador\n",
    "    i=0\n",
    "\n",
    "    if(quantized):\n",
    "        # Instanciar un intérprete de Tensorflow lite\n",
    "        imagenette_quantized_interpreter = tf.lite.Interpreter('imagenettenetTFLitePrunedQuant.tflite')\n",
    "\n",
    "        # Reservar memoria para el modelo\n",
    "        imagenette_quantized_interpreter.allocate_tensors()\n",
    "\n",
    "        # Tensores de entrada y salida\n",
    "        input_details_quantized = imagenette_quantized_interpreter.get_input_details()[0]\n",
    "        output_details_quantized = imagenette_quantized_interpreter.get_output_details()[0]\n",
    "\n",
    "        # Arrays para almacenar resultados\n",
    "        y_pred_quantized = []\n",
    "        y_true = []#np.empty(shape=(3925, 10), dtype=output_details[\"dtype\"])\n",
    "\n",
    "        # Para cada elemento del conjunto de test ...\n",
    "        sample = next(test_batches)\n",
    "        while i<test_batches.__len__():\n",
    "            # Escribimos el tensor en la input de la red neuronal\n",
    "            imagenette_quantized_interpreter.set_tensor(input_details_quantized[\"index\"], sample[0])\n",
    "            # Invocamos al intérprete\n",
    "            init = time.time() # Comenzamos a medir el tiempo\n",
    "            imagenette_quantized_interpreter.invoke()\n",
    "            end = time.time() # Acabamos\n",
    "            times.append(end - init) # Elapsed time\n",
    "            # Guardamos la salida obtenida y la real\n",
    "            y_pred_quantized.append(to_categorical(imagenette_quantized_interpreter.get_tensor(output_details_quantized[\"index\"])[0].argmax(), 10))\n",
    "            y_true.append(sample[1][0])\n",
    "            sample = next(test_batches)\n",
    "            i = i+1\n",
    "            \n",
    "        \n",
    "        # Media de los tiempos de predicción en segs\n",
    "        print(\"Media de los tiempos de ejecución con cuantización: \" + str(statistics.mean(times)) + \"segs\")\n",
    "        accuracy_score = sklearn.metrics.accuracy_score(y_true, y_pred_quantized)\n",
    "        print(\"Accuracy score:\", accuracy_score)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        return accuracy_score\n",
    "\n",
    "    else:\n",
    "        # Instanciar un intérprete de Tensorflow lite\n",
    "        imagenette_interpreter = tf.lite.Interpreter('imagenettenetTFLitePruned.tflite')\n",
    "\n",
    "        # Reservar memoria para el modelo\n",
    "        imagenette_interpreter.allocate_tensors()\n",
    "\n",
    "        # Tensores de entrada y salida\n",
    "        input_details = imagenette_interpreter.get_input_details()[0]\n",
    "        output_details = imagenette_interpreter.get_output_details()[0]\n",
    "\n",
    "        # Arrays para almacenar resultados \n",
    "        y_pred = []#np.empty(shape=(3925, 10), dtype=output_details[\"dtype\"])\n",
    "        y_true = []#np.empty(shape=(3925, 10), dtype=output_details[\"dtype\"])\n",
    "        # Para cada elemento del conjunto de test ...\n",
    "        sample = next(test_batches)\n",
    "        while i<test_batches.__len__():\n",
    "            # Escribimos el tensor en la input de la red neuronal\n",
    "            imagenette_interpreter.set_tensor(input_details[\"index\"], sample[0])\n",
    "            # Invocamos al intérprete\n",
    "            init = time.time() # Comenzamos a medir el tiempo\n",
    "            imagenette_interpreter.invoke()\n",
    "            end = time.time() # Acabamos\n",
    "            times.append(end - init) # Elapsed time\n",
    "            # Guardamos la salida \n",
    "            #print(to_categorical(imagenette_interpreter.get_tensor(output_details[\"index\"])[0].argmax(), 10))\n",
    "            #np.vstack((y_pred, to_categorical(imagenette_interpreter.get_tensor(output_details[\"index\"])[0].argmax(), 10)))\n",
    "            #np.vstack((y_true, sample[1]))\n",
    "            y_pred.append(to_categorical(imagenette_interpreter.get_tensor(output_details[\"index\"])[0].argmax(), 10))\n",
    "            y_true.append(sample[1][0])\n",
    "            sample = next(test_batches)\n",
    "            i = i+1\n",
    "\n",
    "        # Media de los tiempos de predicción en segs\n",
    "        print(\"Media de los tiempos de ejecución sin cuantización: \" + str(statistics.mean(times)) + \"segs\")\n",
    "        # Cálculo de la precisión\n",
    "        y_pred = np.array(y_pred)\n",
    "        y_true = np.array(y_true)\n",
    "        accuracy_score = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "        print(\"Accuracy score:\", accuracy_score)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3925 images belonging to 10 classes.\n",
      "123/123 [==============================] - 20s 164ms/step - loss: 1.0759 - accuracy: 0.7045\n",
      "123/123 [==============================] - 12s 99ms/step - loss: 1.7084 - accuracy: 0.4224\n",
      "Media de los tiempos de ejecución sin cuantización: 0.01931346680707992segs\n",
      "Accuracy score: 0.42242038216560507\n",
      "Media de los tiempos de ejecución con cuantización: 0.03485810565341051segs\n",
      "Accuracy score: 0.4198726114649681\n"
     ]
    }
   ],
   "source": [
    "# Preparar cjto. para ervaluación de modelos en TFLite \n",
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_batches = test_imagegen.flow_from_directory(\"../../datasets/imagenette2-160/val/\", \n",
    "                                   class_mode=\"categorical\", \n",
    "                                   shuffle=True, \n",
    "                                   batch_size=1, \n",
    "                                   target_size=(160, 160))\n",
    "\n",
    "\n",
    "# Comparación de precisión\n",
    "_ , accuracy_tf = imagenettenet.evaluate(val, batch_size=1, verbose=1)\n",
    "_ ,accuracy_tfpruned = model_pruned.evaluate(val, batch_size=1, verbose=1)\n",
    "accuracy_no_quant_tflite = predict_tflite(tflite_model, test_batches, False)\n",
    "accuracy_quant_tflite = predict_tflite(tflite_quant_model, test_batches, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Keras</th>\n",
       "      <td>0.704459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Keras podado</th>\n",
       "      <td>0.422420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorFlow Lite no Cuant.</th>\n",
       "      <td>0.422420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TensorFlow Lite Cuant.</th>\n",
       "      <td>0.419873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Accuracy\n",
       "Model                              \n",
       "Keras                      0.704459\n",
       "Keras podado               0.422420\n",
       "TensorFlow Lite no Cuant.  0.422420\n",
       "TensorFlow Lite Cuant.     0.419873"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(\n",
    "    [[\"Keras\", accuracy_tf],\n",
    "     [\"Keras podado\", accuracy_tfpruned],\n",
    "     [\"TensorFlow Lite no Cuant.\", accuracy_no_quant_tflite],\n",
    "     [\"TensorFlow Lite Cuant.\", accuracy_quant_tflite]],\n",
    "     columns = [\"Model\", \"Accuracy\"], index=\"Model\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "15dad678111f4055199e27812f8fd807e7e8880170b4c46fb7d59063d2f6dd63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
