{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TikwhxGwlqu7",
    "outputId": "fbf50959-f6ab-4470-9f9b-80b797d68a9a"
   },
   "outputs": [],
   "source": [
    "# Dependencias\n",
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import datasets, utils, preprocessing\n",
    "from tensorflow.keras import models, losses, optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from numpy.random import seed\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NvTVuv7OQDu",
    "outputId": "57a74792-1523-4719-cfaa-197f896804ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Comprobar versión de TensorFlow\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "#apaño para un error\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    " \n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "#fin apaño\n",
    "\n",
    "# Fijar semilla\n",
    "seed(1)\n",
    "random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NvTVuv7OQDu",
    "outputId": "57a74792-1523-4719-cfaa-197f896804ad"
   },
   "outputs": [],
   "source": [
    "#Fijar método y porcentaje de poda\n",
    "METHOD = 'random'\n",
    "PERCENT = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RObhOy1plxzm"
   },
   "outputs": [],
   "source": [
    "# Obtener dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GSDelv73lyUW",
    "outputId": "2a46e9ad-67ed-4d40-e600-32f1361e0b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 32, 32, 3)\n",
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Normalizar datos de test y train (originalmente 255 valores)\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test /= 255\n",
    "x_train /= 255\n",
    "\n",
    "img_rows, img_cols = 32, 32\n",
    "num_dim = 3\n",
    "num_classes = 10\n",
    "\n",
    "# Pasar de matriz a vectores\n",
    "#x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, num_dim)\n",
    "#x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, num_dim)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TSH8CS7l0O1",
    "outputId": "9bd98e7b-1ed4-4154-bbf4-11644f2057be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(50000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Codificación One-hot para las clases\n",
    "y_test_oh = to_categorical(y_test, num_classes)\n",
    "y_train_oh = to_categorical(y_train, num_classes)\n",
    "\n",
    "print(y_test_oh.shape)\n",
    "print(y_train_oh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cQvBRMQ7l6dK"
   },
   "outputs": [],
   "source": [
    "# Definición de hiperparámetros\n",
    "learning_rate = 0.1  # learning rate\n",
    "batch_size = 128   # Tamaño del batch\n",
    "epochs = 1  # Número de epochs\n",
    "adam = optimizers.SGD(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "vQbNZj6vmEQM",
    "outputId": "41b74217-ce68-437a-a5a3-651723080a79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLA PARTE DE PRUNING\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LA PARTE DE PRUNING\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 15,001,418\n",
      "Trainable params: 14,991,946\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importar modelo Keras\n",
    "vgg16 = models.load_model('../../models/VGG16_model/vgg16Keras.h5')\n",
    "\n",
    "# Verificar que el modelo es el correcto\n",
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8QQmGYfmEtm",
    "outputId": "a666d038-d446-46a1-b25a-4394a787ebe2"
   },
   "outputs": [],
   "source": [
    "#!pip install folium==0.2.1\n",
    "#!pip install imgaug==0.2.6\n",
    "#!pip install kerassurgeon\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from kerassurgeon import Surgeon, identify\n",
    "from kerassurgeon.operations import delete_channels, delete_layer\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "  \n",
    "def get_filter_weights(model, layer=None):\n",
    "    \"\"\"function to return weights array for one or all conv layers of a Keras model\"\"\"\n",
    "    if layer or layer==0:\n",
    "        weight_array = model.layers[layer].get_weights()[0]\n",
    "        \n",
    "    else:\n",
    "        weights = [model.layers[layer_ix].get_weights()[0] for layer_ix in range(len(model.layers))\\\n",
    "         if 'conv' in model.layers[layer_ix].name]\n",
    "        weight_array = [np.array(i) for i in weights]\n",
    "    \n",
    "    return weight_array\n",
    "\n",
    "def get_filters_l1(model, layer=None):\n",
    "    \"\"\"Returns L1 norm of a Keras model filters at a given conv layer, if layer=None, returns a matrix of norms\n",
    "model is a Keras model\"\"\"\n",
    "    if layer or layer==0:\n",
    "        weights = get_filter_weights(model, layer)\n",
    "        num_filter = len(weights[0,0,0,:])\n",
    "        norms_dict = {}\n",
    "        norms = []\n",
    "        for i in range(num_filter):\n",
    "            l1_norm = np.sum(abs(weights[:,:,:,i]))\n",
    "            norms.append(l1_norm)\n",
    "    else:\n",
    "        weights = get_filter_weights(model)\n",
    "        max_kernels = max([layr.shape[3] for layr in weights])\n",
    "        norms = np.empty((len(weights), max_kernels))\n",
    "        norms[:] = np.NaN\n",
    "        for layer_ix in range(len(weights)):\n",
    "            # compute norm of the filters\n",
    "            kernel_size = weights[layer_ix][:,:,:,0].size\n",
    "            nb_filters = weights[layer_ix].shape[3]\n",
    "            kernels = weights[layer_ix]\n",
    "            l1 = [np.sum(abs(kernels[:,:,:,i])) for i in range(nb_filters)]\n",
    "            # divide by shape of the filters\n",
    "            l1 = np.array(l1) / kernel_size\n",
    "            norms[layer_ix, :nb_filters] = l1\n",
    "    return norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "yFiJt2HimHn0"
   },
   "outputs": [],
   "source": [
    "def get_filters_apoz(model, layer=None):\n",
    "    \n",
    "    # Get a sample of the train set , or should it be the validation set ?\n",
    "    test_generator = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
    "\n",
    "    apoz_generator = test_generator.flow(\n",
    "                x_test,\n",
    "                batch_size = 1,\n",
    "                subset='validation',\n",
    "                shuffle = False)\n",
    "    \n",
    "    if layer or layer ==0:\n",
    "        assert 'conv' in model.layers[layer].name, \"The layer provided is not a convolution layer\"\n",
    "        weights_array = get_filter_weights(model, layer)\n",
    "        act_ix = layer + 1\n",
    "        nb_filters = weights_array.shape[3]\n",
    "        apoz = compute_apoz(model, act_ix, nb_filters, apoz_generator)\n",
    "                \n",
    "    else :\n",
    "        weights_array = get_filter_weights(model)\n",
    "        max_kernels = max([layr.shape[3] for layr in weights_array])\n",
    "\n",
    "        conv_indexes = [i for i, v in enumerate(model.layers) if 'conv' in v.name]\n",
    "        #print('------------------------------------------------')\n",
    "        activations_indexes = [i for i,v in enumerate(model.layers) if 'activation' \\\n",
    "                       in v.name and 'conv' in model.layers[i-1].name]\n",
    "        #for i,v in enumerate(model.layers):\n",
    "          #print(i)\n",
    "          #print(v)\n",
    "        #print('------------------------------------------------')\n",
    "        # create nd array to collect values\n",
    "        apoz = np.zeros((len(weights_array), max_kernels))\n",
    "\n",
    "        for i, act_ix in enumerate(activations_indexes):\n",
    "            # score this sample with our model (trimmed to the layer of interest)\n",
    "            nb_filters = weights_array[i].shape[3]\n",
    "            apoz_layer = compute_apoz(model, act_ix, nb_filters, apoz_generator)\n",
    "            #print('APOZ de la capa {}:'.format(i))\n",
    "            #print(apoz_layer)\n",
    "            apoz[i, :nb_filters] = apoz_layer\n",
    "        \n",
    "    return apoz\n",
    "\n",
    "\n",
    "def compute_apoz(model, layer_ix, nb_filters, generator):\n",
    "    \"\"\"Compute Average percentage of zeros over a layers activation maps\"\"\"\n",
    "    act_layer = model.get_layer(index=layer_ix)\n",
    "    node_index = 0\n",
    "    temp_model = Model(model.inputs,\n",
    "                               act_layer.get_output_at(node_index)\n",
    "                              )\n",
    "\n",
    "\n",
    "            # count the percentage of zeros per activation\n",
    "    a = temp_model.predict_generator(generator,944, workers=3, verbose=1)\n",
    "    activations = a.reshape(a.shape[0]*a.shape[1]*a.shape[2],nb_filters).T\n",
    "    apoz_layer = np.sum(activations == 0, axis=1) / activations.shape[1]\n",
    "    \n",
    "    return apoz_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XhppIK899EpC"
   },
   "outputs": [],
   "source": [
    "#function to return pruned filters with apoz method\n",
    "def prune_apoz(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    if layer or layer==0:\n",
    "        apoz = get_filters_apoz(model,layer)\n",
    "        to_prune = np.argsort(apoz)[::-1][:n_pruned]\n",
    "    \n",
    "    else:\n",
    "        apoz = get_filters_apoz(model)\n",
    "        #print(apoz)\n",
    "        #print('-------------')\n",
    "        to_prune = biggest_indices(apoz, n_pruned)\n",
    "        #print('to prune')\n",
    "        #print(to_prune)\n",
    "    \n",
    "    return to_prune\n",
    "\n",
    "#function to return pruned filters with l1 method\n",
    "def prune_l1(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    if layer or layer==0:\n",
    "        norms = get_filters_l1(model,layer)\n",
    "        to_prune = np.argsort(norms)[:n_pruned]\n",
    "    \n",
    "    else:\n",
    "        norms = get_filters_l1(model)\n",
    "        to_prune = smallest_indices(norms, n_pruned)\n",
    "    \n",
    "    return to_prune\n",
    "\n",
    "def prune_random(model, n_pruned, layer=None):\n",
    "    \"\"\"returns list of indexes of filter to prune or a matrix layer X filter to prune\"\"\"\n",
    "    weights = get_filter_weights(model, layer)\n",
    "    if layer or layer==0:\n",
    "        n_filters = weights.shape[3]\n",
    "        to_prune = np.random.choice(range(n_filters), n_pruned, replace=False)\n",
    "    else:\n",
    "        layer_ix = np.random.choice(len(weights))\n",
    "        filters = weights[layer_ix].shape[3]\n",
    "        filter_ix = np.random.choice(range(filters))\n",
    "        to_prune = [[layer_ix, filter_ix]]\n",
    "\n",
    "        for i in range(n_pruned-1):\n",
    "            while [layer_ix, filter_ix] in to_prune :\n",
    "                #choose layer\n",
    "                layer_ix = np.random.choice(len(weights))\n",
    "                #choose filter \n",
    "                filters = weights[layer_ix].shape[3]\n",
    "                filter_ix = np.random.choice(range(filters))\n",
    "            to_prune.append([layer_ix, filter_ix])\n",
    "\n",
    "        to_prune = np.array(to_prune)\n",
    "    return to_prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tg74IXvcmKmZ"
   },
   "outputs": [],
   "source": [
    "def compute_pruned_count(model, perc=0.1, layer=None):\n",
    "    if layer or layer ==0:\n",
    "        # count nb of filters\n",
    "        nb_filters = model.layers[layer].output_shape[3]\n",
    "    else:\n",
    "        nb_filters = np.sum([model.layers[i].output_shape[3] for i, layer in enumerate(model.layers) \n",
    "                                                                if 'conv' in model.layers[i].name])\n",
    "            \n",
    "    n_pruned = int(np.floor(perc*nb_filters))\n",
    "    return n_pruned\n",
    "\n",
    "\n",
    "def smallest_indices(array, N):\n",
    "    idx = array.ravel().argsort()[:N]\n",
    "    return np.stack(np.unravel_index(idx, array.shape)).T\n",
    "\n",
    "def biggest_indices(array, N):\n",
    "    idx = array.ravel().argsort()[::-1][:N]\n",
    "    return np.stack(np.unravel_index(idx, array.shape)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DRYFjOF6mMXA"
   },
   "outputs": [],
   "source": [
    "from kerassurgeon.operations import delete_channels, delete_layer\n",
    "from kerassurgeon import Surgeon\n",
    "\n",
    "def prune_one_layer(model, pruned_indexes, layer_ix, opt):\n",
    "    \"\"\"Prunes one layer based on a Keras Model, layer index \n",
    "    and indexes of filters to prune\"\"\"\n",
    "    model_pruned = delete_channels(model, model.layers[layer_ix], pruned_indexes)\n",
    "    model_pruned.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=opt,\n",
    "                          metrics=['accuracy'])\n",
    "    return model_pruned\n",
    "\n",
    "def prune_multiple_layers(model, pruned_matrix, opt):\n",
    "    \"\"\"Prunes several layers based on a Keras Model, layer index and matrix \n",
    "    of indexes of filters to prune\"\"\"\n",
    "    conv_indexes = [i for i, v in enumerate(model.layers) if 'conv' in v.name]\n",
    "    layers_to_prune = np.unique(pruned_matrix[:,0])\n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    to_prune = pruned_matrix\n",
    "    to_prune[:,0] = np.array([conv_indexes[i] for i in to_prune[:,0]])\n",
    "    layers_to_prune = np.unique(to_prune[:,0])\n",
    "    for layer_ix in layers_to_prune :\n",
    "        pruned_filters = [x[1] for x in to_prune if x[0]==layer_ix]\n",
    "        print('filtros a podar:')\n",
    "        print(pruned_filters)\n",
    "        pruned_layer = model.layers[layer_ix]\n",
    "        print('capa a podar:')\n",
    "        print(pruned_layer)\n",
    "        surgeon.add_job('delete_channels', pruned_layer, channels=pruned_filters)\n",
    "    \n",
    "    model_pruned = surgeon.operate()\n",
    "    model_pruned.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QngxSqW3mOXi"
   },
   "outputs": [],
   "source": [
    "def prune_model(model, perc, opt, method='l1', layer=None):\n",
    "    \"\"\"Prune a Keras model using different methods\n",
    "    Arguments:\n",
    "        model: Keras Model object\n",
    "        perc: a float between 0 and 1\n",
    "        method: method to prune, can be one of ['l1','apoz','random']\n",
    "    Returns:\n",
    "        A pruned Keras Model object\n",
    "    \n",
    "    \"\"\"\n",
    "    assert method in ['l1','apoz','random'], \"Invalid pruning method\"\n",
    "    assert perc >=0 and perc <1, \"Invalid pruning percentage\"\n",
    "    \n",
    "    \n",
    "    n_pruned = compute_pruned_count(model, perc, layer)\n",
    "    \n",
    "    if method =='l1':\n",
    "        to_prune = prune_l1(model, n_pruned, layer)    \n",
    "    if method =='apoz':\n",
    "        to_prune = prune_apoz(model, n_pruned, layer)\n",
    "    if method =='random':\n",
    "        to_prune = prune_random(model, n_pruned, layer)    \n",
    "    if layer or layer ==0:\n",
    "        model_pruned = prune_one_layer(model, to_prune, layer, opt)\n",
    "    else:\n",
    "        model_pruned = prune_multiple_layers(model, to_prune, opt)\n",
    "            \n",
    "    return model_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqnPEc4amQu2",
    "outputId": "7acae651-8407-4ed0-ca1c-c0c06ff6140c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtros a podar:\n",
      "[16, 22, 45, 4, 24, 60, 12, 55, 57, 29, 54, 61, 42, 50, 19, 46, 26, 30, 27, 28, 39, 53, 32, 31, 58, 37, 17, 33, 1, 25, 21, 40, 51, 15, 63, 36, 43, 18, 0, 7, 13, 47, 23, 14, 56, 3, 6, 8, 20, 62, 38, 49, 34, 44, 5, 11, 59, 2, 35, 10, 9, 41, 48, 52]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa907969198>\n",
      "filtros a podar:\n",
      "[12, 0, 57, 49, 30, 50, 53, 14, 47, 2, 23, 4, 39, 43, 18, 38, 6, 58, 10, 5, 62, 27, 34, 29, 11, 13, 1, 54, 60, 7, 44, 25, 32, 33, 20, 52, 17, 21, 45, 56, 51, 42, 19, 61, 41, 35, 15, 9, 46, 36, 8, 24, 26, 63, 55, 31, 37, 48, 16, 59, 3, 28, 22]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f04bacc0>\n",
      "filtros a podar:\n",
      "[68, 15, 87, 10, 76, 96, 108, 71, 78, 31, 79, 100, 110, 38, 106, 99, 28, 30, 42, 102, 36, 93, 52, 119, 94, 125, 111, 120, 77, 127, 122, 49, 82, 23, 117, 86, 98, 115, 20, 44, 123, 118, 67, 109, 92, 80, 35, 34, 25, 18, 2, 11, 40, 74, 113, 56, 21, 61, 8, 58, 7, 91, 63, 14, 97, 22, 70, 59, 126, 112, 89, 81, 33, 104, 51, 24, 60, 3, 29, 66, 13, 0, 57, 114, 47, 32, 48, 41, 103, 50, 45, 90, 46, 121, 37, 62, 39, 12, 101, 69, 5, 116, 9, 73, 64, 85, 75, 26]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa9a6ee7da0>\n",
      "filtros a podar:\n",
      "[47, 68, 41, 103, 38, 0, 97, 25, 116, 32, 19, 67, 81, 111, 106, 46, 12, 34, 77, 80, 56, 121, 98, 63, 48, 66, 62, 42, 31, 28, 96, 124, 94, 110, 59, 27, 57, 107, 125, 22, 18, 76, 69, 78, 64, 119, 26, 93, 71, 114, 61, 85, 73, 52, 5, 88, 10, 15, 100, 83, 14, 60, 115, 92, 44, 1, 95, 79, 29, 4, 74, 55, 89, 72, 84, 45, 16, 30, 17, 50, 23, 101, 122, 54, 35, 117, 58, 36, 49, 109, 75, 70, 24, 11, 21, 120, 2, 86, 104, 53, 126, 127, 108, 99, 113, 82, 6, 118, 87, 65, 43, 33, 105]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f04c2b70>\n",
      "filtros a podar:\n",
      "[254, 139, 155, 30, 103, 57, 10, 116, 83, 32, 206, 151, 249, 89, 131, 23, 204, 112, 185, 109, 228, 87, 146, 250, 26, 76, 173, 133, 38, 62, 248, 128, 52, 161, 70, 187, 15, 227, 105, 9, 246, 235, 237, 163, 207, 74, 197, 17, 238, 82, 66, 142, 208, 16, 212, 98, 31, 104, 129, 234, 58, 5, 73, 43, 180, 59, 149, 107, 177, 135, 200, 50, 166, 63, 220, 144, 3, 126, 101, 22, 64, 29, 203, 49, 68, 121, 134, 148, 176, 92, 240, 118, 81, 174, 152, 245, 115, 251, 201, 124, 67, 186, 162, 24, 60, 39, 224, 160, 46, 94, 230, 241, 222, 88, 120, 56, 154, 127, 190, 48, 11, 13, 182, 25, 61, 179, 232, 4, 28, 194, 132, 178, 215, 221, 45, 150, 102, 198, 8, 97, 211, 34, 99, 219, 75, 6, 123, 86, 175, 14, 253, 19, 91, 65, 110, 69, 72, 106, 71, 169, 138, 214, 7, 188, 111, 1, 36, 210]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f0414cc0>\n",
      "filtros a podar:\n",
      "[235, 79, 146, 57, 198, 145, 231, 164, 248, 40, 221, 175, 94, 174, 226, 73, 137, 93, 2, 233, 52, 209, 147, 250, 136, 7, 105, 22, 196, 155, 113, 249, 251, 43, 38, 121, 36, 118, 97, 230, 18, 125, 111, 179, 26, 207, 194, 50, 217, 170, 205, 127, 210, 239, 182, 69, 55, 142, 90, 120, 20, 30, 172, 59, 112, 80, 65, 190, 10, 144, 188, 107, 134, 161, 181, 102, 200, 206, 163, 240, 131, 14, 185, 166, 143, 62, 220, 173, 186, 135, 77, 67, 13, 5, 83, 195, 47, 242, 92, 24, 119, 48, 103, 117, 149, 53, 223, 244, 232, 64, 255, 178, 68, 183, 152, 215, 140, 241, 87, 34, 82, 45, 46, 214, 15, 88, 16, 252, 229, 160, 202, 130, 89, 253, 133, 51, 128, 110, 115, 238, 122, 171, 197, 141, 86, 228, 189, 9, 245, 71, 54, 75, 159, 218, 192, 165, 21, 4, 114, 138, 162, 29, 180, 204, 37, 6, 106, 124, 60, 12, 177]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f043aef0>\n",
      "filtros a podar:\n",
      "[57, 149, 9, 52, 96, 198, 15, 176, 229, 175, 169, 153, 240, 0, 247, 207, 219, 76, 98, 140, 13, 194, 221, 122, 242, 180, 97, 179, 5, 230, 88, 45, 128, 146, 103, 212, 193, 132, 161, 197, 250, 25, 142, 2, 1, 129, 4, 137, 83, 154, 64, 189, 151, 248, 205, 21, 107, 249, 254, 116, 148, 152, 33, 102, 200, 131, 182, 7, 84, 46, 209, 59, 106, 225, 155, 185, 208, 105, 164, 82, 156, 32, 211, 217, 203, 143, 215, 138, 27, 196, 14, 171, 87, 39, 49, 109, 204, 163, 165, 17, 10, 159, 177, 130, 50, 166, 213, 53, 201, 243, 124, 118, 80, 162, 86, 38, 18, 3, 172, 77, 91, 89, 73, 16, 232, 26, 100, 111, 235, 69, 181, 192, 202, 147, 234, 117, 127, 188, 160, 139, 251, 31, 157, 8, 244, 23, 44, 24, 37, 60, 168, 66, 186, 35, 29, 85, 218, 51, 241, 227, 41, 11, 90, 246, 104, 75, 206, 22, 220, 178]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f03db0f0>\n",
      "filtros a podar:\n",
      "[237, 471, 478, 319, 387, 282, 381, 143, 281, 243, 183, 301, 377, 176, 309, 144, 227, 389, 508, 423, 64, 230, 112, 469, 450, 140, 506, 124, 454, 359, 91, 380, 466, 500, 246, 162, 353, 251, 166, 33, 214, 416, 55, 354, 253, 95, 365, 368, 77, 17, 284, 232, 134, 187, 18, 221, 202, 307, 509, 356, 278, 215, 494, 496, 488, 185, 296, 66, 7, 198, 213, 355, 448, 130, 390, 207, 160, 262, 437, 451, 306, 3, 268, 312, 254, 491, 461, 427, 311, 71, 88, 249, 45, 502, 244, 229, 70, 406, 127, 384, 327, 412, 369, 465, 346, 69, 2, 155, 436, 196, 270, 128, 321, 324, 241, 63, 280, 211, 483, 293, 459, 258, 463, 181, 285, 276, 180, 233, 208, 129, 103, 138, 337, 326, 101, 184, 47, 76, 315, 472, 122, 367, 16, 239, 431, 378, 58, 0, 399, 81, 290, 329, 121, 165, 115, 105, 484, 242, 146, 255, 341, 252, 342, 409, 53, 395, 426, 272, 410, 438, 170, 199, 1, 234, 497, 400, 147, 443, 476, 373, 460, 362, 224, 86, 57, 226, 102, 106, 441, 8, 156, 446, 83, 168, 118, 159, 59, 31, 344, 248, 411, 231, 32, 418, 247, 333, 167, 510, 97, 188, 15]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f039a1d0>\n",
      "filtros a podar:\n",
      "[216, 30, 497, 288, 253, 75, 202, 338, 217, 443, 507, 462, 84, 113, 211, 226, 344, 365, 28, 18, 405, 234, 168, 374, 197, 39, 172, 263, 427, 358, 506, 376, 343, 68, 492, 445, 241, 449, 307, 209, 38, 179, 437, 286, 180, 411, 274, 392, 303, 378, 46, 238, 247, 31, 317, 478, 439, 399, 243, 242, 314, 210, 311, 127, 215, 78, 452, 299, 174, 441, 62, 170, 214, 310, 308, 434, 0, 510, 198, 17, 483, 63, 490, 153, 203, 183, 375, 290, 77, 396, 159, 381, 130, 80, 440, 82, 460, 29, 346, 268, 261, 59, 469, 341, 73, 471, 199, 404, 407, 137, 373, 270, 493, 66, 323, 334, 456, 169, 151, 485, 476, 415, 503, 382, 486, 64, 157, 499, 20, 192, 250, 347, 421, 473, 325, 464, 267, 465, 144, 337, 61, 406, 160, 122, 91, 383, 2, 36, 377, 121, 7, 426, 111, 461, 25, 364, 332, 256, 420, 275, 342, 309, 354, 488, 425, 295, 409, 6, 175, 105, 293, 282, 423, 301, 116, 235, 1, 350, 269, 277, 195, 225, 12, 134, 246, 87, 106, 262, 152, 388, 90, 500, 351, 37, 304, 148, 442, 467, 133, 498, 450, 57, 380, 142, 103, 287, 97, 333, 145, 54, 181, 389, 489, 220, 329, 466, 146, 231, 69, 52, 49]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f03a8cc0>\n",
      "filtros a podar:\n",
      "[203, 178, 241, 393, 367, 104, 338, 450, 320, 112, 309, 490, 441, 377, 306, 42, 312, 333, 323, 406, 489, 152, 153, 96, 124, 199, 355, 229, 107, 197, 388, 68, 474, 28, 43, 232, 444, 498, 176, 279, 452, 141, 390, 348, 392, 239, 58, 83, 31, 163, 159, 405, 217, 100, 324, 438, 21, 417, 505, 319, 308, 65, 174, 35, 470, 283, 413, 252, 372, 235, 302, 204, 288, 418, 414, 303, 128, 226, 161, 186, 38, 116, 73, 421, 478, 133, 375, 261, 222, 341, 329, 503, 339, 191, 276, 458, 132, 351, 416, 397, 447, 33, 185, 209, 228, 103, 496, 0, 483, 465, 177, 196, 169, 14, 24, 272, 422, 316, 310, 29, 384, 57, 325, 72, 139, 376, 245, 440, 207, 336, 295, 365, 300, 407, 473, 477, 394, 423, 492, 242, 148, 63, 360, 127, 469, 378, 370, 106, 77, 137, 289, 321, 129, 334, 347, 69, 212, 495, 194, 181, 435, 126, 396, 368, 326, 481, 345, 192, 34, 275, 508, 67, 403, 201, 437, 64, 105, 462, 151, 123, 205, 506, 7, 144, 22, 269, 224, 10, 404, 27, 78, 145, 117, 244, 331, 189, 44, 113, 429, 480, 165, 23, 491, 20, 247, 389]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f0359550>\n",
      "filtros a podar:\n",
      "[121, 308, 279, 20, 136, 276, 194, 205, 123, 469, 184, 476, 282, 383, 200, 12, 396, 416, 411, 31, 214, 150, 466, 149, 39, 338, 303, 467, 56, 151, 302, 397, 295, 91, 7, 254, 407, 344, 363, 347, 21, 77, 291, 85, 502, 307, 369, 449, 376, 269, 216, 388, 9, 405, 298, 452, 500, 462, 133, 154, 83, 410, 399, 146, 45, 192, 499, 163, 228, 380, 264, 221, 319, 267, 37, 445, 332, 67, 325, 48, 296, 70, 81, 404, 351, 415, 134, 274, 168, 229, 238, 93, 24, 423, 358, 488, 129, 425, 196, 287, 68, 167, 378, 324, 465, 428, 162, 406, 426, 142, 413, 173, 61, 401, 304, 119, 434, 501, 446, 385, 290, 479, 231, 114, 87, 2, 248, 461, 130, 15, 220, 409, 244, 58, 483, 55, 433, 86, 190, 219, 370, 328, 53, 454, 103, 417, 42, 321, 164, 109, 197, 199, 314, 472, 52, 432, 27, 331, 318, 443, 459, 340, 491, 117, 107, 189, 71, 414, 94, 355, 364, 508, 493, 105, 300, 450, 11, 243, 226, 384, 368, 418, 330, 206, 468, 171, 76, 139, 345, 54, 349, 271, 122, 457, 18, 470, 145, 207, 453, 230]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f03188d0>\n",
      "filtros a podar:\n",
      "[76, 149, 263, 134, 177, 35, 398, 154, 86, 410, 460, 112, 43, 105, 442, 406, 419, 32, 156, 445, 506, 389, 434, 133, 236, 99, 174, 221, 95, 435, 509, 147, 229, 88, 377, 46, 161, 61, 53, 458, 322, 387, 380, 338, 482, 139, 400, 318, 31, 117, 426, 219, 336, 425, 307, 97, 131, 346, 479, 438, 279, 332, 350, 414, 353, 242, 300, 455, 437, 276, 103, 477, 467, 497, 69, 85, 202, 227, 184, 501, 158, 302, 79, 186, 157, 366, 78, 358, 3, 347, 190, 87, 59, 169, 352, 24, 469, 180, 357, 64, 456, 491, 207, 12, 492, 290, 152, 225, 246, 293, 416, 275, 472, 321, 8, 428, 499, 488, 115, 218, 326, 166, 330, 83, 66, 413, 490, 100, 239, 252, 167, 11, 504, 74, 2, 4, 201, 153, 268, 254, 409, 51, 281, 33, 171, 125, 224, 481, 26, 62, 399, 93, 298, 320, 349, 339, 475, 375, 140, 313, 111, 128, 296, 489, 452, 28, 277, 168, 72, 333, 376, 188, 486, 36, 464, 122, 222, 228, 427, 306, 130, 440, 463, 420, 282, 143, 309, 329, 211, 137, 205, 303, 379, 172, 110, 381, 108, 232, 466, 92, 146, 70]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f0331160>\n",
      "filtros a podar:\n",
      "[72, 390, 490, 413, 209, 74, 43, 337, 148, 489, 103, 234, 55, 222, 211, 271, 243, 150, 105, 51, 131, 37, 376, 455, 192, 280, 165, 52, 54, 362, 145, 62, 116, 327, 239, 203, 420, 187, 506, 296, 70, 368, 219, 264, 174, 329, 320, 191, 473, 64, 469, 210, 349, 97, 173, 440, 365, 253, 35, 82, 409, 361, 491, 460, 354, 87, 16, 419, 38, 138, 371, 343, 204, 255, 101, 472, 293, 259, 288, 441, 118, 463, 372, 25, 0, 322, 229, 198, 338, 510, 341, 63, 325, 262, 359, 113, 48, 474, 9, 201, 284, 309, 53, 350, 168, 212, 197, 96, 153, 143, 41, 178, 429, 185, 56, 252, 130, 59, 333, 273, 119, 321, 339, 217, 18, 428, 91, 120, 308, 67, 231, 75, 123, 478, 373, 246, 404, 134, 346, 344, 220, 44, 104, 415, 421, 24, 275, 226, 470, 78, 156, 223, 425, 476, 357, 126, 480, 122, 214, 213, 141, 227, 386, 454, 81, 300, 389, 285, 414, 49, 23, 163, 225, 167, 102, 399, 395, 158, 277, 459, 508, 497, 45, 301, 270, 408, 378, 146, 363, 109, 358, 509, 169, 453, 342, 486, 445, 492, 433, 439, 6, 467, 89, 345, 248, 76, 11, 397, 5, 377, 133, 488, 251, 382, 129]\n",
      "capa a podar:\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa8f02da978>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b8c2cdea2f82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Podar modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPERCENT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMETHOD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel_pruned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-77bccfc22c4f>\u001b[0m in \u001b[0;36mprune_model\u001b[0;34m(model, perc, opt, method, layer)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mmodel_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_one_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_prune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmodel_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_multiple_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_prune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_pruned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-895c4cc08830>\u001b[0m in \u001b[0;36mprune_multiple_layers\u001b[0;34m(model, pruned_matrix, opt)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'delete_channels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruned_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruned_filters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mmodel_pruned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurgeon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     model_pruned.compile(loss='categorical_crossentropy',\n\u001b[1;32m     33\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfg-env/lib/python3.6/site-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36moperate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# Perform surgery at this node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mod_func_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# Finish rebuilding model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfg-env/lib/python3.6/site-packages/kerassurgeon/surgeon.py\u001b[0m in \u001b[0;36m_delete_channels\u001b[0;34m(self, node, inputs, input_masks, channels, layer_name)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mtemp_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_delete_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# This call is needed to initialise input_shape and output_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mtemp_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0mnew_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delete_channel_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfg-env/lib/python3.6/site-packages/kerassurgeon/utils.py\u001b[0m in \u001b[0;36msingle_element\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Podar modelo\n",
    "model_pruned = prune_model(vgg16, PERCENT, adam, method=METHOD)\n",
    "model_pruned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune\n",
    "history = model_pruned.fit(x_train, y_train_oh, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(x_test, y_test_oh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHvxB8gIGmSm"
   },
   "outputs": [],
   "source": [
    "# Guardar a disco modelo de Keras en formato h5 y h5py\n",
    "model_pruned.save('vgg16KerasPruned.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Tensorflow Lite sin Cuantización\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\n",
    "tflite_model = converter.convert()\n",
    "# Guardar a disco\n",
    "open(\"vgg16TFLitePruned.tflite\", \"wb\").write(tflite_model)\n",
    "\n",
    "# Convertir a Tensorflow Lite con Cuantización de rango dinámico\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "      x_test_rd = np.expand_dims(x_test, -1)  \n",
    "      yield [x_test_rd[i].astype(np.float32)]\n",
    "\n",
    "converter_q = tf.lite.TFLiteConverter.from_keras_model(model_pruned)\n",
    "converter_q.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quant_model = converter_q.convert()\n",
    "# Guardar a disco\n",
    "open(\"vgg16TFLitePrunedQuant.tflite\", \"wb\").write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PARTE DE COMPARACIÓN DE TAMAÑOS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de tamaños\n",
    "print(\"El tamaño del modelo comprimido en Keras es %.2f bytes\" % get_gzipped_model_size('../../models/VGG16_model/vgg16Keras.h5'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido en Keras PODADO es %.2f bytes\" % get_gzipped_model_size('vgg16KerasPruned.h5'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido PODADO y en TFlite sin cuantizar es %.2f bytes\" % get_gzipped_model_size('vgg16TFLitePruned.tflite'))\n",
    "print(\"------------------------------------------------------\")\n",
    "print(\"El tamaño del modelo comprimido PODADO y en TFlite CUANTIZADO es %.2f bytes\" % get_gzipped_model_size('vgg16TFLitePrunedQuant.tflite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PARTE DE COMPARACIÓN DE PRECISIÓN Y TOMA DE TIEMPOS\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import statistics\n",
    "\n",
    "# Probaremos la precisión del modelo de Keras sin podar\n",
    "scores = vgg16.evaluate(x_test, y_test_oh)\n",
    "print(\"\\n%s: %.2f%%\" % (vgg16.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test, y_true, quantized):\n",
    "\n",
    "    #lista de tiempos \n",
    "    times=[]\n",
    "\n",
    "    # Preparar el cjto de test\n",
    "    x_test_ = x_test.copy()\n",
    "    x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "    if(quantized):\n",
    "        # Instanciar un intérprete de Tensorflow lite\n",
    "        VGG_quantized_interpreter = tf.lite.Interpreter('vgg16TFLitePrunedQuant.tflite')\n",
    "\n",
    "        # Reservar memoria para el modelo\n",
    "        VGG_quantized_interpreter.allocate_tensors()\n",
    "\n",
    "        # Tensores de entrada y salida\n",
    "        input_details_quantized = VGG_quantized_interpreter.get_input_details()[0]\n",
    "        output_details_quantized = VGG_quantized_interpreter.get_output_details()[0]\n",
    "\n",
    "        # Arrays para almacenar resultados\n",
    "        y_pred_quantized = np.empty([x_test_.shape[0], 10], dtype=output_details_quantized[\"dtype\"])\n",
    "\n",
    "        # Para cada elemento del conjunto de test ...\n",
    "        for i in range(len(x_test_)):\n",
    "            # Escribimos el tensor en la input de la red neuronal\n",
    "            VGG_quantized_interpreter.set_tensor(input_details_quantized[\"index\"], [x_test_[i]])\n",
    "            # Invocamos al intérprete\n",
    "            init = time.time() # Comenzamos a medir el tiempo\n",
    "            VGG_quantized_interpreter.invoke()\n",
    "            end = time.time() # Acabamos\n",
    "            times.append(end - init) # Elapsed time\n",
    "            # Guardamos la salida \n",
    "            y_pred_quantized[i,:] = to_categorical(VGG_quantized_interpreter.get_tensor(output_details_quantized[\"index\"])[0].argmax(), 10)\n",
    "        \n",
    "        # Media de los tiempos de predicción en segs\n",
    "        print(\"Media de los tiempos de ejecución con cuantización: \" + str(statistics.mean(times)) + \"segs\")\n",
    "        accuracy_score = sklearn.metrics.accuracy_score(y_true, y_pred_quantized)\n",
    "        print(\"Accuracy score:\", accuracy_score)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        return accuracy_score\n",
    "\n",
    "    else:\n",
    "        # Instanciar un intérprete de Tensorflow lite\n",
    "        VGG_interpreter = tf.lite.Interpreter('vgg16TFLitePruned.tflite')\n",
    "\n",
    "        # Reservar memoria para el modelo\n",
    "        VGG_interpreter.allocate_tensors()\n",
    "\n",
    "        # Tensores de entrada y salida\n",
    "        input_details = VGG_interpreter.get_input_details()[0]\n",
    "        output_details = VGG_interpreter.get_output_details()[0]\n",
    "\n",
    "        # Arrays para almacenar resultados\n",
    "        y_pred = np.empty([x_test_.shape[0], 10], dtype=output_details[\"dtype\"])\n",
    "\n",
    "        # Para cada elemento del conjunto de test ...\n",
    "        for i in range(len(x_test_)):\n",
    "            # Escribimos el tensor en la input de la red neuronal\n",
    "            VGG_interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "            # Invocamos al intérprete\n",
    "            init = time.time() # Comenzamos a medir el tiempo\n",
    "            VGG_interpreter.invoke()\n",
    "            end = time.time() # Acabamos\n",
    "            times.append(end - init) # Elapsed time\n",
    "            # Guardamos la salida \n",
    "            y_pred[i,:] = to_categorical(VGG_interpreter.get_tensor(output_details[\"index\"])[0].argmax(), 10)\n",
    "            \n",
    "        # Media de los tiempos de predicción en segs\n",
    "        print(\"Media de los tiempos de ejecución sin cuantización: \" + str(statistics.mean(times)) + \"segs\")\n",
    "        # Cálculo de la precisión\n",
    "        accuracy_score = sklearn.metrics.accuracy_score(y_true, y_pred)\n",
    "        print(\"Accuracy score:\", accuracy_score)\n",
    "        #print(y_pred)\n",
    "        \n",
    "        return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparación de precisión\n",
    "_ , accuracy_tf = vgg16.evaluate(x_test, y_test_oh, batch_size=1, verbose=1)\n",
    "_ ,accuracy_tfpruned = model_pruned.evaluate(x_test, y_test_oh, batch_size=1, verbose=1)\n",
    "accuracy_no_quant_tflite = predict_tflite(tflite_model, x_test, y_test_oh, False)\n",
    "accuracy_quant_tflite = predict_tflite(tflite_quant_model, x_test, y_test_oh, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(\n",
    "    [[\"Keras\", accuracy_tf],\n",
    "     [\"Keras podado\", accuracy_tfpruned],\n",
    "     [\"TensorFlow Lite no Cuant.\", accuracy_no_quant_tflite],\n",
    "     [\"TensorFlow Lite Cuant.\", accuracy_quant_tflite]],\n",
    "     columns = [\"Model\", \"Accuracy\"], index=\"Model\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "15dad678111f4055199e27812f8fd807e7e8880170b4c46fb7d59063d2f6dd63"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
